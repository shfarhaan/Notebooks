{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6031380c",
   "metadata": {},
   "source": [
    "# Class 13: Anomaly Detection + Forecasting (ARIMA & Isolation Forest)\n",
    "\n",
    "**Lab:** Detect anomalies in power-system data; **Project update:** model selection\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "Two complementary lenses on time series:\n",
    "\n",
    "* **Forecast-then-flag (ARIMA):** predict the next value and mark points where the **residual** (actual − forecast) is unusually large. Great for *temporal* structure.\n",
    "* **Feature-then-flag (Isolation Forest):** compute rolling features (mean, std, slope, etc.) and flag outliers in that multivariate space. Great for *shape* anomalies across windows.\n",
    "\n",
    "Together, they’re peanut butter + jelly for power signals.\n",
    "\n",
    "---\n",
    "\n",
    "### Lecture Notes (pocket guide)\n",
    "\n",
    "* **Stationarity:** ARIMA expects stable mean/variance; use **differencing (I)**, **ACF/PACF** to choose **p (AR)** and **q (MA)**.\n",
    "* **ARIMA(p,d,q):** AR (auto-regressive), I (differencing), MA (moving average). **SARIMA** adds seasonality (P,D,Q,s).\n",
    "* **Forecast-based anomalies:** large residuals or high prediction intervals breach → anomaly candidates.\n",
    "* **Isolation Forest (IF):** isolates points by random splits; fewer splits → more anomalous. Use rolling windows to create features.\n",
    "* **Evaluation:** if you know some injected anomalies, compute precision/recall; otherwise, inspect with plots and domain constraints.\n",
    "\n",
    "---\n",
    "\n",
    "## Demo Notebook (Colab-style cells)\n",
    "\n",
    "### 0) Make a synthetic power load series with anomalies (daily pattern + spikes/drops)\n",
    "\n",
    "```python\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "np.random.seed(13)\n",
    "\n",
    "# 60 days of hourly load (1440 samples for minute-level; we'll use hourly for clarity)\n",
    "hours = 24 * 120  # 120 days\n",
    "t = np.arange(hours)\n",
    "# Base: daily sinusoidal demand + slow trend + noise\n",
    "daily = 50 + 10*np.sin(2*np.pi*t/24)\n",
    "trend = 0.02*(t/24)  # gentle growth per day\n",
    "noise = np.random.normal(0, 1.5, size=hours)\n",
    "y = daily + trend + noise\n",
    "\n",
    "# Inject anomalies: spikes and sudden drops (10 total)\n",
    "anom_idx = np.random.choice(np.arange(48, hours-48), size=10, replace=False)\n",
    "y_anom = y.copy()\n",
    "y_anom[anom_idx[:5]] += np.random.uniform(15, 25, size=5)   # spikes\n",
    "y_anom[anom_idx[5:]] -= np.random.uniform(15, 25, size=5)   # dips\n",
    "\n",
    "ts = pd.Series(y_anom, index=pd.date_range(\"2024-01-01\", periods=hours, freq=\"H\"), name=\"load_MW\")\n",
    "labels = pd.Series(0, index=ts.index)\n",
    "labels.iloc[anom_idx] = 1  # ground truth labels (1 = anomaly)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "ts.plot(lw=1)\n",
    "plt.title(\"Synthetic Power Load with Injected Anomalies\")\n",
    "plt.ylabel(\"Load (MW)\"); plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### 1) Forecast-then-flag with (S)ARIMA (seasonal daily cycle)\n",
    "\n",
    "```python\n",
    "# We'll use SARIMA with daily seasonality s=24\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split: first 100 days train, last 20 days test\n",
    "split = ts.index[int(len(ts)* (100/120))]\n",
    "train, test = ts[:split], ts[split:]\n",
    "\n",
    "# Simple SARIMA order guess (p,d,q) x (P,D,Q,24)\n",
    "order = (2,1,2)\n",
    "seasonal_order = (1,1,1,24)\n",
    "\n",
    "model = SARIMAX(train, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "res = model.fit(disp=False)\n",
    "\n",
    "# Forecast the test horizon\n",
    "fc = res.get_forecast(steps=len(test))\n",
    "pred = fc.predicted_mean\n",
    "ci = fc.conf_int(alpha=0.05)  # 95% PI\n",
    "\n",
    "ax = test.plot(label=\"actual\", figsize=(10,3))\n",
    "pred.plot(ax=ax, label=\"forecast\")\n",
    "ax.fill_between(ci.index, ci.iloc[:,0], ci.iloc[:,1], color=\"gray\", alpha=0.2, label=\"95% PI\")\n",
    "plt.title(\"SARIMA Forecast on Holdout\")\n",
    "plt.ylabel(\"Load (MW)\"); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "# Residuals on the whole series using one-step ahead (dynamic) forecasting\n",
    "full = pd.concat([train, test])\n",
    "fit_full = SARIMAX(full, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "fitted = fit_full.fittedvalues  # in-sample one-step predictions\n",
    "resid = full - fitted\n",
    "resid.name = \"residual\"\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "resid.plot(lw=0.8)\n",
    "plt.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "plt.title(\"Residuals (One-step Ahead)\")\n",
    "plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### 2) Residual-based anomaly score (z-score or PI breach)\n",
    "\n",
    "```python\n",
    "# Z-score of residuals using rolling std for local adaptivity\n",
    "roll_std = resid.rolling(24*7, min_periods=24).std()  # 1-week window\n",
    "z = (resid / (roll_std + 1e-6)).abs()\n",
    "\n",
    "# Flag anomalies: z > 3 or actual outside 95% PI (on test range)\n",
    "z_thresh = 3.0\n",
    "flag_z = (z > z_thresh).astype(int)\n",
    "\n",
    "# Precision/Recall vs ground truth (on full series since we labeled all)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(\"ARIMA residual Z>3 | Precision:\", precision_score(labels, flag_z, zero_division=0),\n",
    "      \"Recall:\", recall_score(labels, flag_z),\n",
    "      \"F1:\", f1_score(labels, flag_z))\n",
    "\n",
    "# Visualize signals and anomaly markers\n",
    "ax = ts.plot(figsize=(10,3), lw=1, label=\"load\")\n",
    "(ts[flag_z.astype(bool)]).plot(ax=ax, marker=\"o\", ls=\"none\", ms=5, label=\"ARIMA anomalies\")\n",
    "plt.title(\"Anomalies by Forecast Residuals\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### 3) Feature-then-flag with Isolation Forest (windowed features)\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Build rolling-window features (e.g., 24-hour window)\n",
    "w = 24\n",
    "df_feat = pd.DataFrame({\n",
    "    \"mean\": ts.rolling(w).mean(),\n",
    "    \"std\": ts.rolling(w).std(),\n",
    "    \"p2p\": ts.rolling(w).max() - ts.rolling(w).min(),\n",
    "    \"slope\": ts.diff().rolling(w).mean(),   # average first difference\n",
    "})\n",
    "df_feat = df_feat.dropna()\n",
    "\n",
    "# Fit Isolation Forest on features (unsupervised)\n",
    "if_model = IsolationForest(n_estimators=300, contamination=0.01, random_state=0)\n",
    "if_scores = if_model.fit_predict(df_feat)  # -1 = anomaly, 1 = normal\n",
    "flag_if = pd.Series((if_scores == -1).astype(int), index=df_feat.index)\n",
    "\n",
    "# Align with labels (intersecting index)\n",
    "y_true = labels.reindex(df_feat.index).fillna(0).astype(int)\n",
    "print(\"IsolationForest | Precision:\", precision_score(y_true, flag_if, zero_division=0),\n",
    "      \"Recall:\", recall_score(y_true, flag_if),\n",
    "      \"F1:\", f1_score(y_true, flag_if))\n",
    "\n",
    "ax = ts.plot(figsize=(10,3), lw=1, label=\"load\")\n",
    "(ts[flag_if.astype(bool)]).plot(ax=ax, marker=\"x\", ls=\"none\", ms=5, label=\"IF anomalies\")\n",
    "plt.title(\"Anomalies by Isolation Forest\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### 4) Compare methods and combine (logical OR to be conservative)\n",
    "\n",
    "```python\n",
    "# Align ARIMA flags to IF index\n",
    "flag_z_aligned = flag_z.reindex(df_feat.index).fillna(0).astype(int)\n",
    "flag_union = ((flag_if == 1) | (flag_z_aligned == 1)).astype(int)\n",
    "print(\"Union (IF ∪ ARIMA) | Precision:\", precision_score(y_true, flag_union, zero_division=0),\n",
    "      \"Recall:\", recall_score(y_true, flag_union),\n",
    "      \"F1:\", f1_score(y_true, flag_union))\n",
    "\n",
    "ax = ts.plot(figsize=(10,3), lw=1, label=\"load\")\n",
    "(ts[flag_union.astype(bool)]).plot(ax=ax, marker=\"o\", ls=\"none\", ms=5, label=\"Union anomalies\")\n",
    "plt.title(\"Combined Anomaly Flags\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Classworks (5) — Skeleton Code (students fill in)\n",
    "\n",
    "### Classwork 1: Visual sanity & labels\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 1: CREATE/LOAD SERIES + LABELS\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Create a time series 'ts' (hourly, >= 60 days) with daily pattern + noise.\n",
    "# 2) Inject at least 8 anomalies (spikes/drops) and store indices in 'anom_idx'.\n",
    "# 3) Make a 'labels' Series aligned to ts (1=anomaly else 0).\n",
    "# 4) Plot ts + mark anomalies.\n",
    "\n",
    "# ts = pd.Series(..., index=pd.date_range(..., freq=\"H\"))\n",
    "# anom_idx = [...]\n",
    "# labels = pd.Series(0, index=ts.index); labels.iloc[anom_idx] = 1\n",
    "# ax = ts.plot(figsize=(10,3), lw=1)\n",
    "# ts.iloc[anom_idx].plot(ax=ax, ls=\"none\", marker=\"o\", ms=5)\n",
    "# plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### Classwork 2: Fit SARIMA and compute residual z-scores\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 2: (S)ARIMA RESIDUALS\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Choose SARIMA orders (p,d,q)x(P,D,Q,24) and fit on train split.\n",
    "# 2) Compute one-step-ahead fitted values on full series.\n",
    "# 3) Residuals = actual - fitted. Compute rolling std and z-scores.\n",
    "# 4) Flag z > 3 as anomaly.\n",
    "\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# order = (??, ??, ??); seasonal_order = (??, ??, ??, 24)\n",
    "# res = SARIMAX(ts[:split], order=order, seasonal_order=seasonal_order).fit(disp=False)\n",
    "# fit_full = SARIMAX(ts, order=order, seasonal_order=seasonal_order).fit(disp=False)\n",
    "# fitted = fit_full.fittedvalues\n",
    "# resid = ts - fitted\n",
    "# z = (resid / (resid.rolling(24*7, min_periods=24).std() + 1e-6)).abs()\n",
    "# flag_arima = (z > 3).astype(int)\n",
    "```\n",
    "\n",
    "### Classwork 3: Isolation Forest on rolling features\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 3: ISOLATION FOREST\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Build rolling features (mean, std, p2p, slope) with window=24.\n",
    "# 2) Fit IsolationForest(contamination=0.02) on features.\n",
    "# 3) Get anomaly flags (-1→1).\n",
    "# 4) Compute precision/recall vs labels (align indexes).\n",
    "\n",
    "# w = 24\n",
    "# df_feat = pd.DataFrame({\n",
    "#   \"mean\": ts.rolling(w).mean(),\n",
    "#   \"std\": ts.rolling(w).std(),\n",
    "#   \"p2p\": ts.rolling(w).max() - ts.rolling(w).min(),\n",
    "#   \"slope\": ts.diff().rolling(w).mean(),\n",
    "# }).dropna()\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# if_model = IsolationForest(n_estimators=300, contamination=0.02, random_state=0)\n",
    "# flags_if = pd.Series((if_model.fit_predict(df_feat)==-1).astype(int), index=df_feat.index)\n",
    "# y_true = labels.reindex(df_feat.index).fillna(0).astype(int)\n",
    "# # print precision/recall/F1\n",
    "```\n",
    "\n",
    "### Classwork 4: Combine detectors & tune thresholds\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 4: COMBINE & TUNE\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Make union and intersection of ARIMA and IF flags.\n",
    "# 2) Sweep z-threshold from {2.0, 2.5, 3.0, 3.5}.\n",
    "# 3) For each threshold, compute Precision/Recall/F1 of union.\n",
    "# 4) Choose a setting prioritizing Recall (justify).\n",
    "\n",
    "# z_values = [2.0, 2.5, 3.0, 3.5]\n",
    "# rows = []\n",
    "# for zt in z_values:\n",
    "#     flag_arima_zt = ((z > zt).astype(int)).reindex(df_feat.index).fillna(0).astype(int)\n",
    "#     union = ((flag_arima_zt==1) | (flags_if==1)).astype(int)\n",
    "#     # compute P/R/F1 vs y_true\n",
    "#     rows.append({\"z\": zt, \"prec\": ..., \"rec\": ..., \"f1\": ...})\n",
    "# pd.DataFrame(rows)\n",
    "```\n",
    "\n",
    "### Classwork 5: Optional SARIMA hyperparam sweep (quick search)\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 5: SARIMA QUICK SWEEP\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Try small grids for p,d,q in {0,1,2}, P,D,Q in {0,1} with s=24 (keep combinations reasonable).\n",
    "# 2) Fit on train, compute forecast RMSE on validation slice.\n",
    "# 3) Pick best order and refit on full series; report anomaly F1 with z=3.\n",
    "\n",
    "# from itertools import product\n",
    "# pdq = [(p,d,q) for p,d,q in product([0,1,2],[0,1],[0,1,2])]\n",
    "# PDQ = [(P,D,Q,24) for P,D,Q in product([0,1],[0,1],[0,1])]\n",
    "# # loop (keep to small subset to finish fast)\n",
    "# # track validation RMSE; store best (order, seasonal_order)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Lab: Detect Anomalies in Power-System Data\n",
    "\n",
    "**Goal:** Use **both** approaches on your series:\n",
    "\n",
    "1. **SARIMA residual z-score** (threshold tune): produce an anomaly timeline and precision/recall vs labels.\n",
    "2. **Isolation Forest on rolling features**: same metrics and a plot.\n",
    "3. **Compare & combine**: union vs intersection; pick a policy for plant ops (favor catching all true anomalies → higher recall, or minimizing false alarms → higher precision).\n",
    "4. Save a one-page lab note: dataset, chosen params, plots, metrics, and an operational recommendation.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Update (Model Selection)\n",
    "\n",
    "* Write 5–8 lines addressing:\n",
    "\n",
    "  * Which detector aligns with your project’s tolerance (misses vs false alarms)?\n",
    "  * If your data has strong seasonality, lean **SARIMA/Prophet** for explainability; if multivariate shape matters, lean **IF / One-Class SVM / Autoencoder**.\n",
    "  * What features or external regressors (weather, calendar) would boost reliability?\n",
    "  * Next step: small **pilot threshold** and on-call workflow (who investigates a flag, within how long).\n",
    "\n",
    "---\n",
    "\n",
    "### Wrap-up / Homework Challenge\n",
    "\n",
    "* Add a **prediction-interval breach** rule: flag anomalies when actual is **outside 99% PI** from SARIMA; compare to z-score.\n",
    "* Try **contamination tuning** for IF in {0.005, 0.01, 0.02}; plot precision-recall trade-off and choose a setting for a high-risk substation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
