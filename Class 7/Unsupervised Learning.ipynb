{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9dd6427",
   "metadata": {},
   "source": [
    "\n",
    "# Class 7: Unsupervised Learning — K-means & PCA (Sensor Pattern Discovery)\n",
    "\n",
    "### Overview\n",
    "\n",
    "When labels are unknown (which is most of real life), clustering and dimensionality reduction help you “see the shape” of data. We’ll standardize features, try different values of **k**, score clusters, and use **PCA** to project high-dimensional sensor features to 2D for intuition and plotting.\n",
    "\n",
    "### Lecture Notes (short + teachable)\n",
    "\n",
    "* **Unsupervised learning**: find structure without labels.\n",
    "* **K-means**: partitions points into k clusters by minimizing within-cluster variance. Sensitive to scale → **always standardize** features. Use **elbow** (inertia) & **silhouette** to choose k.\n",
    "* **PCA**: rotates to orthogonal axes capturing maximum variance; good for visualization and noise reduction. Watch explained variance ratio.\n",
    "* **Workflow**:\n",
    "\n",
    "  1. Build features (means, stds, slopes, frequency energy, etc.)\n",
    "  2. **Scale** → **PCA** (optional for viz) → **K-means**\n",
    "  3. Inspect clusters; interpret with domain sense (EE: operating states, fault regimes, sensor placement effects)\n",
    "\n",
    "---\n",
    "\n",
    "## Demo Notebook (Colab-style cells)\n",
    "\n",
    "### 0) Setup: synthesize multi-state sensor data (self-contained)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# Simulate 3 operating states for a sensor window: Normal / Drift / Noisy\n",
    "n = 450\n",
    "n_per = n // 3\n",
    "\n",
    "# Features per window (engineer these like in Class 3/4):\n",
    "# mean_v, std_v, slope, p2p (peak-to-peak), energy (sum of squares proxy)\n",
    "normal = np.column_stack([\n",
    "    np.random.normal(3.20, 0.02, n_per),   # mean\n",
    "    np.random.normal(0.03, 0.01, n_per),   # std\n",
    "    np.random.normal(0.00, 0.01, n_per),   # slope\n",
    "    np.random.normal(0.20, 0.05, n_per),   # peak-to-peak\n",
    "    np.random.normal(1.00, 0.10, n_per),   # energy\n",
    "])\n",
    "\n",
    "drift = np.column_stack([\n",
    "    np.random.normal(3.32, 0.03, n_per),\n",
    "    np.random.normal(0.04, 0.01, n_per),\n",
    "    np.random.normal(0.03, 0.01, n_per),   # positive slope\n",
    "    np.random.normal(0.25, 0.05, n_per),\n",
    "    np.random.normal(1.20, 0.12, n_per),\n",
    "])\n",
    "\n",
    "noisy = np.column_stack([\n",
    "    np.random.normal(3.20, 0.04, n_per),\n",
    "    np.random.normal(0.12, 0.03, n_per),   # high std\n",
    "    np.random.normal(0.00, 0.02, n_per),\n",
    "    np.random.normal(0.45, 0.08, n_per),   # large p2p\n",
    "    np.random.normal(1.60, 0.20, n_per),   # high energy\n",
    "])\n",
    "\n",
    "X = np.vstack([normal, drift, noisy])\n",
    "cols = [\"mean_v\",\"std_v\",\"slope\",\"p2p\",\"energy\"]\n",
    "df = pd.DataFrame(X, columns=cols)\n",
    "df.head()\n",
    "```\n",
    "\n",
    "### 1) Standardize, try K values, elbow + silhouette\n",
    "\n",
    "```python\n",
    "from collections import OrderedDict\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(df)\n",
    "\n",
    "inertia = []\n",
    "sil_scores = []\n",
    "\n",
    "K = range(2, 8)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=0)\n",
    "    labels = km.fit_predict(Xs)\n",
    "    inertia.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(Xs, labels))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].plot(list(K), inertia, marker=\"o\")\n",
    "ax[0].set_title(\"Elbow: Inertia vs k\"); ax[0].set_xlabel(\"k\"); ax[0].set_ylabel(\"Inertia\"); ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(list(K), sil_scores, marker=\"o\")\n",
    "ax[1].set_title(\"Silhouette vs k\"); ax[1].set_xlabel(\"k\"); ax[1].set_ylabel(\"Silhouette\"); ax[1].grid(True)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "OrderedDict(zip(K, sil_scores))\n",
    "```\n",
    "\n",
    "### 2) Fit K-means with chosen k (e.g., 3), inspect cluster centers\n",
    "\n",
    "```python\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, n_init=20, random_state=0)\n",
    "labels = kmeans.fit_predict(Xs)\n",
    "df[\"cluster\"] = labels\n",
    "\n",
    "# Unscale centers back to feature space for interpretability\n",
    "centers_std = kmeans.cluster_centers_\n",
    "centers = pd.DataFrame(scaler.inverse_transform(centers_std), columns=cols)\n",
    "centers[\"cluster\"] = range(k)\n",
    "centers\n",
    "```\n",
    "\n",
    "### 3) PCA to 2D for visualization\n",
    "\n",
    "```python\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "Xp = pca.fit_transform(Xs)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Cumulative variance:\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for c in range(k):\n",
    "    idx = (labels == c)\n",
    "    plt.scatter(Xp[idx,0], Xp[idx,1], s=15, label=f\"cluster {c}\", alpha=0.8)\n",
    "plt.title(\"Clusters in PCA space\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.grid(True); plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 4) Feature importance (PCA loadings) + center comparison\n",
    "\n",
    "```python\n",
    "loadings = pd.DataFrame(pca.components_, columns=cols, index=[\"PC1\",\"PC2\"])\n",
    "loadings  # how each original feature contributes to PCs\n",
    "\n",
    "# Compare cluster centers across features\n",
    "centers.set_index(\"cluster\")\n",
    "```\n",
    "\n",
    "### 5) Quick interpretation helper\n",
    "\n",
    "```python\n",
    "summary = centers.copy()\n",
    "summary[\"interpretation\"] = [\n",
    "    \"Higher mean/slope → drift-like?\",\n",
    "    \"High std/p2p/energy → noisy regime?\",\n",
    "    \"Baseline stats → normal?\",\n",
    "][:k]\n",
    "summary\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Classworks (5) — Skeleton Code (students fill in)\n",
    "\n",
    "### Classwork 1: Standardize + elbow method\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 1: SCALE + ELBOW\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Standardize your DataFrame 'df' (columns in list 'cols').\n",
    "# 2) For k in 2..8, fit KMeans and store inertia.\n",
    "# 3) Plot inertia vs k; pick a candidate k.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# Xs = scaler.???(df[cols])\n",
    "\n",
    "# inertias = []\n",
    "# for k in range(2, 9):\n",
    "#     km = KMeans(n_clusters=???, n_init=20, random_state=0)\n",
    "#     km.???(Xs)\n",
    "#     inertias.append(km.???)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(range(2,9), inertias, marker=\"o\")\n",
    "# plt.xlabel(\"k\"); plt.ylabel(\"Inertia\"); plt.title(\"Elbow\")\n",
    "# plt.grid(True); plt.show()\n",
    "```\n",
    "\n",
    "### Classwork 2: Silhouette score sweep\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 2: SILHOUETTE SWEEP\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Using Xs, compute silhouette_score for k=2..8.\n",
    "# 2) Make a small table of k vs silhouette.\n",
    "# 3) Choose k with reasoning.\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "\n",
    "# rows = []\n",
    "# for k in range(2, 9):\n",
    "#     km = KMeans(n_clusters=k, n_init=20, random_state=0).fit(Xs)\n",
    "#     labels = km.labels_\n",
    "#     sil = silhouette_score(???, ???)\n",
    "#     rows.append({\"k\": k, \"silhouette\": sil})\n",
    "# pd.DataFrame(rows)\n",
    "```\n",
    "\n",
    "### Classwork 3: PCA 2D projection + colored clusters\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 3: PCA VISUALIZATION\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Fit PCA(n_components=2) on Xs.\n",
    "# 2) Transform Xs -> Xp (2D).\n",
    "# 3) Fit KMeans with your chosen k; scatter PC1 vs PC2 colored by cluster.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pca = PCA(n_components=???, random_state=0)\n",
    "# Xp = pca.???(Xs)\n",
    "# print(\"Explained variance ratio:\", pca.???)\n",
    "\n",
    "# km = KMeans(n_clusters=???, n_init=20, random_state=0).fit(Xs)\n",
    "# labels = km.labels_\n",
    "\n",
    "# plt.figure(figsize=(6,5))\n",
    "# for c in range(???: ???):   # iterate cluster ids\n",
    "#     idx = (labels == c)\n",
    "#     plt.scatter(Xp[idx,0], Xp[idx,1], s=15, label=f\"cluster {c}\")\n",
    "# plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(\"Clusters in PCA space\")\n",
    "# plt.grid(True); plt.legend(); plt.show()\n",
    "```\n",
    "\n",
    "### Classwork 4: Interpret centers (unscale) and name clusters\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 4: INTERPRET CLUSTERS\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Take your fitted KMeans centers in standardized space.\n",
    "# 2) Inverse-transform back to original units (scaler.inverse_transform).\n",
    "# 3) Put into a DataFrame and add a 'label_name' column with your interpretation.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# centers_std = km.cluster_centers_\n",
    "# centers_orig = scaler.???(centers_std)\n",
    "# centers_df = pd.DataFrame(centers_orig, columns=cols)\n",
    "# centers_df[\"label_name\"] = [\"???\", \"???\", \"???\"][:centers_df.shape[0]]\n",
    "# centers_df\n",
    "```\n",
    "\n",
    "### Classwork 5: PCA loadings (feature contributions) + mini report\n",
    "\n",
    "```python\n",
    "# ==========================================\n",
    "# CLASSWORK 5: PCA LOADINGS + REPORT\n",
    "# ==========================================\n",
    "# Task:\n",
    "# 1) Get PCA components_ and create a loadings table with columns=cols and index=[\"PC1\",\"PC2\"].\n",
    "# 2) Identify top-2 contributing features for each PC.\n",
    "# 3) Write 2-3 lines explaining how PCs relate to your domain (e.g., std/energy ~ noise axis).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loadings = pd.DataFrame(pca.???, columns=cols, index=[\"PC1\",\"PC2\"])\n",
    "# # For each PC, find absolute contribution rankings\n",
    "# top_pc1 = loadings.loc[\"PC1\"].abs().sort_values(ascending=False).head(2)\n",
    "# top_pc2 = loadings.loc[\"PC2\"].abs().sort_values(ascending=False).head(2)\n",
    "# print(\"Top PC1 features:\", top_pc1.index.tolist())\n",
    "# print(\"Top PC2 features:\", top_pc2.index.tolist())\n",
    "\n",
    "# # TODO (text cell or print statements): brief interpretation\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Wrap-up / Homework Challenge\n",
    "\n",
    "* **Stability check**: rerun K-means with different `random_state` values; do clusters/centers change much? Quantify using **Adjusted Rand Index** after refitting, or compare center distances.\n",
    "* **Practical twist**: add a rare “faulty” regime (e.g., 5% of samples with extreme std/energy). Can K-means isolate it? If not, try **k=4** or mark the smallest, farthest cluster as *anomaly*. Write a 4-line note: what would your team do next (collect more data? change features? try Isolation Forest in Class 13)?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
